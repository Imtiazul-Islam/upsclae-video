{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- 1. SETUP & INSTALLATION ---\n# Installs necessary libraries and sets up directory structure.\n\n!pip install --upgrade --quiet \\\n    \"git+https://github.com/huggingface/diffusers\" \\\n    \"gguf\" \\\n    \"accelerate\" \\\n    \"peft\" \\\n    \"ipywidgets\"\n\nimport os\nimport shutil\n\n# Define Paths\n# We move outputs to a clean folder, separate from models\nOUTPUT_DIR = \"/kaggle/working/generated_images\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"‚úÖ Environment Ready.\")\nprint(f\"üìÇ Images will be saved to: {OUTPUT_DIR}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. LOAD MODEL & OPTIMIZE MEMORY ---\nimport torch\nimport gc\nfrom huggingface_hub import hf_hub_download\nfrom diffusers import ZImagePipeline, ZImageTransformer2DModel, GGUFQuantizationConfig\n\n# Configuration\nGGUF_REPO = \"unsloth/Z-Image-Turbo-GGUF\"\nGGUF_FILE = \"z-image-turbo-Q8_0.gguf\"\n\nprint(\"‚è≥ Downloading Model (approx 7GB)...\")\ntry:\n    local_gguf_path = hf_hub_download(GGUF_REPO, GGUF_FILE)\n    \n    print(\"‚è≥ Loading Transformer...\")\n    transformer = ZImageTransformer2DModel.from_single_file(\n        local_gguf_path,\n        quantization_config=GGUFQuantizationConfig(compute_dtype=torch.bfloat16),\n        dtype=torch.bfloat16,\n    )\n\n    print(\"‚è≥ Initializing Pipeline...\")\n    pipe = ZImagePipeline.from_pretrained(\n        \"Tongyi-MAI/Z-Image-Turbo\",\n        transformer=transformer,\n        torch_dtype=torch.bfloat16,\n    )\n\n    # --- CRITICAL MEMORY OPTIMIZATIONS FOR P100 ---\n    # 1. CPU Offload: Keeps text encoder in RAM until needed\n    pipe.enable_model_cpu_offload()\n    \n    # 2. VAE Tiling: Process image in small overlapping squares (Saves ~3-4GB VRAM)\n    pipe.vae.enable_tiling()\n    \n    # 3. VAE Slicing: Decode batches one by one (Saves VRAM)\n    pipe.vae.enable_slicing()\n\n    print(\"\\n‚úÖ Model Loaded Successfully.\")\n    print(\"üõ°Ô∏è Memory Protection Enabled (Tiling + Slicing active).\")\n\nexcept Exception as e:\n    print(f\"\\n‚ùå Error loading model: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 3. ROBUST STUDIO UI (V2) ---\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nimport random\nfrom datetime import datetime\n\n# --- SAFE RESOLUTION PRESETS ---\n# These are mathematically guaranteed to work (Divisible by 16)\nRATIO_PRESETS = {\n    \"Landscape (16:9)\": (1280, 720),\n    \"Portrait (9:16)\": (720, 1280),\n    \"Square (1:1)\": (1024, 1024),\n    \"Cinematic (21:9)\": (1536, 640),\n}\n\n# --- WIDGETS ---\nstyle = {'description_width': '80px'}\nlayout_full = widgets.Layout(width='98%')\nlayout_half = widgets.Layout(width='48%')\n\n# Header\nlbl_header = widgets.HTML(\"<h2>üé® Z-Image Turbo Studio</h2>\")\n\n# 1. Prompt Area\ntxt_prompt = widgets.Textarea(\n    placeholder='Describe your image... (e.g. detailed human heart, anatomical drawing, 8k, masterpiece)',\n    description='Prompt:',\n    rows=3,\n    style=style,\n    layout=layout_full\n)\n\ntxt_negative = widgets.Textarea(\n    value='low quality, bad anatomy, worst quality, text, watermark, blurry, ugly, deformed',\n    placeholder='Things to exclude...',\n    description='Negative:',\n    rows=1,\n    style=style,\n    layout=layout_full\n)\n\n# 2. Controls\ndd_ratio = widgets.Dropdown(\n    options=list(RATIO_PRESETS.keys()),\n    value='Landscape (16:9)',\n    description='Ratio:',\n    style=style,\n    layout=layout_half\n)\n\nnum_seed = widgets.IntText(\n    value=-1,\n    description='Seed (-1=Rnd):',\n    style={'description_width': '100px'},\n    layout=layout_half\n)\n\nslider_steps = widgets.IntSlider(\n    value=10,       # 10 is a safe sweet spot for Turbo\n    min=4, max=30,\n    description='Steps:',\n    style=style,\n    layout=layout_half\n)\n\nslider_cfg = widgets.FloatSlider(\n    value=2.0,\n    min=1.0, max=10.0, step=0.5,\n    description='CFG:',\n    style=style,\n    layout=layout_half\n)\n\nbtn_gen = widgets.Button(\n    description=' GENERATE',\n    button_style='success',\n    icon='bolt',\n    layout=widgets.Layout(width='100%', height='50px')\n)\n\nout_log = widgets.Output()\nout_img = widgets.Output()\n\n# --- GENERATION LOGIC ---\ndef run_generation(b):\n    with out_log:\n        clear_output()\n        \n        # 1. Get Resolution DIRECTLY from Presets (Fixes the 100x100 bug)\n        selected_ratio = dd_ratio.value\n        w, h = RATIO_PRESETS[selected_ratio]\n        \n        # 2. Get Seed\n        current_seed = num_seed.value\n        if current_seed == -1:\n            current_seed = random.randint(0, 2**32-1)\n            \n        prompt = txt_prompt.value\n        if not prompt:\n            print(\"‚ö†Ô∏è Prompt is empty! using default.\")\n            prompt = \"A beautiful landscape\"\n\n        print(f\"‚öôÔ∏è Config: {w}x{h} ({selected_ratio})\")\n        print(f\"‚ö° Steps: {slider_steps.value} | CFG: {slider_cfg.value}\")\n        print(f\"üå± Seed: {current_seed}\")\n        print(f\"üìù Prompt: {prompt[:80]}...\")\n\n        # 3. Clean VRAM\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        try:\n            # 4. Run Pipeline\n            generator = torch.Generator(\"cuda\").manual_seed(current_seed)\n            \n            with torch.inference_mode():\n                image = pipe(\n                    prompt=prompt,\n                    negative_prompt=txt_negative.value,\n                    height=h,\n                    width=w,\n                    num_inference_steps=slider_steps.value,\n                    guidance_scale=slider_cfg.value,\n                    generator=generator\n                ).images[0]\n            \n            # 5. Save & Display\n            ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n            filename = f\"Img_{ts}_{w}x{h}_s{current_seed}.png\"\n            save_path = os.path.join(OUTPUT_DIR, filename)\n            image.save(save_path)\n            \n            print(f\"‚úÖ Saved: {filename}\")\n            \n            with out_img:\n                clear_output()\n                display(image)\n\n        except Exception as e:\n            print(f\"\\n‚ùå Error: {e}\")\n            print(f\"Diagnostic: Requested {w}x{h}. If this fails, restart kernel.\")\n\nbtn_gen.on_click(run_generation)\n\n# --- UI ASSEMBLY ---\nui_v2 = widgets.VBox([\n    lbl_header,\n    widgets.VBox([txt_prompt, txt_negative], layout=widgets.Layout(margin='0 0 10px 0')),\n    widgets.HBox([dd_ratio, num_seed]),\n    widgets.HBox([slider_steps, slider_cfg]),\n    widgets.Box([btn_gen], layout=widgets.Layout(margin='20px 0')),\n    out_log,\n    out_img\n])\n\ndisplay(ui_v2)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}